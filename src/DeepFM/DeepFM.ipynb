{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from gensim.models import FastText\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/train'\n",
    "train_df = pd.read_csv(os.path.join(data_path, 'train_ratings.csv')) # 전체 학습 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_data = pd.read_csv(os.path.join(data_path, 'years.tsv'), sep='\\t')\n",
    "writer_data = pd.read_csv(os.path.join(data_path, 'writers.tsv'), sep='\\t')\n",
    "title_data = pd.read_csv(os.path.join(data_path, 'titles.tsv'), sep='\\t')\n",
    "genre_data = pd.read_csv(os.path.join(data_path, 'genres.tsv'), sep='\\t')\n",
    "director_data = pd.read_csv(os.path.join(data_path, 'directors.tsv'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['watch_date'] = pd.to_datetime(train_df['time'], unit='s')\n",
    "train_df.drop(columns=['time'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.merge(train_df, title_data, on='item', how='left').merge(year_data, on='item', how='left')\n",
    "\n",
    "# 시계열 정보 추출\n",
    "all_data['watch_year'] = all_data['watch_date'].dt.year\n",
    "# all_data['watch_month'] = all_data['watch_date'].dt.month\n",
    "# all_data['watch_day'] = all_data['watch_date'].dt.day\n",
    "\n",
    "# 아이템의 year와의 차이\n",
    "# all_data['year_diff'] = all_data['watch_year'] - all_data['year']\n",
    "\n",
    "# watch_date 컬럼 삭제\n",
    "all_data.drop(columns=['watch_date'], inplace=True)\n",
    "\n",
    "# 34048번 영화 제목 수정\n",
    "all_data.loc[all_data['item'] == 34048, 'title'] = all_data.loc[all_data['item'] == 34048, 'title'] + \" Extended\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title에서 연도 추출\n",
    "all_data['extracted_year'] = all_data['title'].apply(lambda x: int(re.search(r'\\((\\d{4})\\)', x).group(1)) if re.search(r'\\((\\d{4})\\)', x) else None)\n",
    "\n",
    "# 결측치 채우기\n",
    "all_data['year'] = all_data['year'].fillna(all_data['extracted_year'])\n",
    "# int32로 변환\n",
    "all_data['year'] = all_data['year'].astype('int32')\n",
    "\n",
    "# 불필요한 열 삭제\n",
    "all_data.drop(columns=['extracted_year'], inplace=True)\n",
    "\n",
    "# title에서 연도 제거\n",
    "all_data['title'] = all_data['title'].apply(lambda x: re.sub(r'\\s*\\(\\d{4}\\)', '', x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title 데이터를 공백으로 분리한 토큰 리스트로 변환\n",
    "all_data['title_tokens'] = all_data['title'].apply(lambda x: x.split())\n",
    "\n",
    "# FastText 모델 학습\n",
    "fasttext_model = FastText(\n",
    "    sentences=all_data['title_tokens'],  # Tokenized titles\n",
    "    vector_size=50,                     # Embedding dimension\n",
    "    window=3,                           # Context window size\n",
    "    min_count=1,                        # 최소 등장 횟수 (1로 설정하면 모든 단어 학습)\n",
    "    sg=1,                               # Skip-gram 사용 (0: CBOW, 1: Skip-gram)\n",
    "    epochs=10                           # 학습 에폭 수\n",
    ")\n",
    "\n",
    "# 각 Title의 임베딩 생성 (단어 벡터의 평균 사용)\n",
    "def get_title_embedding(title_tokens, model, vector_size):\n",
    "    vectors = [model.wv[word] for word in title_tokens if word in model.wv]\n",
    "    if len(vectors) > 0:\n",
    "        return np.mean(vectors, axis=0)  # 단어 벡터의 평균\n",
    "    else:\n",
    "        return np.zeros(vector_size)    # OOV일 경우 0 벡터 반환\n",
    "\n",
    "# Title 임베딩 추가\n",
    "embedding_dim = 50\n",
    "all_data['title_embedding'] = all_data['title_tokens'].apply(\n",
    "    lambda x: get_title_embedding(x, fasttext_model, embedding_dim)\n",
    ")\n",
    "\n",
    "all_data = all_data.drop(columns=['title_tokens', 'title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genre_data에서 장르를 리스트로 변환\n",
    "genre_data['genre_list'] = genre_data['genre'].apply(lambda x: x.split(','))\n",
    "\n",
    "# item별로 장르 리스트를 결합\n",
    "genres_per_item = genre_data.groupby('item')['genre_list'].agg(lambda x: sum(x, [])).reset_index()\n",
    "\n",
    "# all_data에 병합\n",
    "all_data = pd.merge(all_data, genres_per_item, on='item', how='left')\n",
    "\n",
    "# 모든 고유 장르 리스트 추출\n",
    "all_genres = set([genre for sublist in all_data['genre_list'] for genre in sublist])\n",
    "all_genres = sorted(list(all_genres))  # 정렬된 고유 장르 리스트\n",
    "\n",
    "# 장르별 인덱스 매핑\n",
    "genre_to_idx = {genre: idx for idx, genre in enumerate(all_genres)}\n",
    "\n",
    "\n",
    "# Multi-hot Encoding 변환 함수\n",
    "def encode_genre_list(genre_list, genre_to_idx, num_genres):\n",
    "    multi_hot = np.zeros(num_genres, dtype=int)\n",
    "    for genre in genre_list:\n",
    "        if genre in genre_to_idx:\n",
    "            multi_hot[genre_to_idx[genre]] = 1\n",
    "    return multi_hot\n",
    "\n",
    "# Multi-hot Encoding 적용\n",
    "num_genres = len(all_genres)\n",
    "all_data['genre_embedding'] = all_data['genre_list'].apply(lambda x: encode_genre_list(x, genre_to_idx, num_genres))\n",
    "\n",
    "all_data = all_data.drop(columns=['genre_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "user_encoder = LabelEncoder()\n",
    "item_encoder = LabelEncoder()\n",
    "\n",
    "# 유저와 아이템을 고유한 정수로 변환\n",
    "all_data['user_encoded'] = user_encoder.fit_transform(all_data['user'])\n",
    "all_data['item_encoded'] = item_encoder.fit_transform(all_data['item'])\n",
    "columns = ['user_encoded', 'item_encoded'] + [col for col in all_data.columns if col not in ['user_encoded', 'item_encoded']]\n",
    "all_data = all_data[columns]\n",
    "\n",
    "# User ID 매핑\n",
    "user_id_mapping = dict(zip(all_data['user_encoded'], all_data['user']))\n",
    "\n",
    "# Item ID 매핑\n",
    "item_id_mapping = dict(zip(all_data['item_encoded'], all_data['item']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepFM(nn.Module):\n",
    "    def __init__(self, input_dims, embedding_dim, mlp_dims, drop_rate=0.1):\n",
    "        super(DeepFM, self).__init__()\n",
    "        \n",
    "        self.total_input_dim = sum(input_dims)\n",
    "        self.embedding_dim = embedding_dim\n",
    "        # 범주형 변수의 개수\n",
    "        self.num_categorical_features = len(input_dims)\n",
    "        continuous_columns = ['genre_embedding', 'year']\n",
    "        # 연속형 변수의 총 차원 수\n",
    "        self.total_continuous_feature_dim = sum(1 if col in ['year'] else all_data[col].iloc[0].shape[0] for col in continuous_columns if col in all_data.columns)\n",
    "\n",
    "        print(f\"Input Dims: {input_dims}\")\n",
    "        print(f\"num_categorical_features: {self.num_categorical_features}\")\n",
    "        print(f\"total_continuous_feature_dim: {self.total_continuous_feature_dim}\")\n",
    "        print(f\"embedding_dim: {self.embedding_dim}\")\n",
    "\n",
    "        # Embedding layer for categorical variables\n",
    "        self.embedding = nn.Embedding(self.total_input_dim, embedding_dim)\n",
    "\n",
    "        # FM components\n",
    "        self.fc = nn.Embedding(self.total_input_dim, 1)\n",
    "        self.bias = nn.Parameter(torch.zeros((1,)))\n",
    "\n",
    "        # Continuous features' linear transformation\n",
    "        self.continuous_linear = nn.Linear(self.total_continuous_feature_dim, self.total_continuous_feature_dim * embedding_dim)\n",
    "        self.embedding_dim_total = self.num_categorical_features * embedding_dim + self.total_continuous_feature_dim * embedding_dim\n",
    "\n",
    "        # MLP components\n",
    "        self.mlp_input_dim = (self.num_categorical_features * embedding_dim) + (self.total_continuous_feature_dim * embedding_dim)\n",
    "        print(f\"Calculated MLP Input Dimension: {self.mlp_input_dim}\")\n",
    "        mlp_layers = []\n",
    "        for i, dim in enumerate(mlp_dims):\n",
    "            if i == 0:\n",
    "                mlp_layers.append(nn.Linear(self.mlp_input_dim, dim))\n",
    "            else:\n",
    "                mlp_layers.append(nn.Linear(mlp_dims[i-1], dim))\n",
    "            mlp_layers.append(nn.ReLU())\n",
    "            mlp_layers.append(nn.Dropout(drop_rate))\n",
    "        mlp_layers.append(nn.Linear(mlp_dims[-1], 1))\n",
    "        self.mlp_layers = nn.Sequential(*mlp_layers)\n",
    "\n",
    "    def fm(self, x_categorical, x_continuous):\n",
    "        # Embedding lookup for categorical variables\n",
    "        embed_x = self.embedding(x_categorical)  # (batch_size, num_categorical_features, embedding_dim) = (2048, 2, 64)\n",
    "\n",
    "        # Transform continuous features\n",
    "        x_continuous_transformed = self.continuous_linear(x_continuous.float())  # (batch_size, total_continuous_feature_dim * embedding_dim) = (2048, 20*64=1280)\n",
    "        x_continuous_transformed = x_continuous_transformed.view(\n",
    "            -1, self.total_continuous_feature_dim, self.embedding_dim\n",
    "        )  # (batch_size, total_continuous_feature_dim, embedding_dim) = (2048, 20, 64)\n",
    "\n",
    "        # Concatenate embeddings and continuous features\n",
    "        fm_input = torch.cat([embed_x, x_continuous_transformed], dim=1)  # (batch_size, total_features, embedding_dim) = (2048, 22, 64)\n",
    "\n",
    "        # Linear term\n",
    "        linear_part = torch.sum(self.fc(x_categorical), dim=1) + self.bias  # (batch_size, 1)\n",
    "        linear_part += torch.sum(x_continuous, dim=1, keepdim=True)\n",
    "\n",
    "        # Pairwise interaction term\n",
    "        square_of_sum = torch.sum(fm_input, dim=1) ** 2  # (batch_size, embedding_dim) = (2048, 64)\n",
    "        sum_of_square = torch.sum(fm_input ** 2, dim=1)  # (batch_size, embedding_dim) = (2048, 64)\n",
    "        interaction_part = 0.5 * (square_of_sum - sum_of_square).sum(dim=1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        fm_y = linear_part + interaction_part\n",
    "        return fm_y\n",
    "\n",
    "    def mlp(self, x_categorical, x_continuous):\n",
    "        # Embedding lookup for categorical variables\n",
    "        embed_x = self.embedding(x_categorical)  # (batch_size, num_categorical_features, embedding_dim)\n",
    "        # print(f\"MLP - Embed_x Shape: {embed_x.shape}\")  # 확인: (1024, num_categorical_features, embedding_dim)\n",
    "        embed_x = embed_x.view(embed_x.size(0), -1)  # Flatten embeddings\n",
    "        # print(f\"MLP - Flattened Embed_x Shap!!!e: {embed_x.shape}\")  # 확인: (1024, num_categorical_features * embedding_dim)\n",
    "\n",
    "        # Transform continuous features\n",
    "        x_continuous_transformed = self.continuous_linear(x_continuous)  # (batch_size, total_continuous_feature_dim * embedding_dim)\n",
    "        # print(f\"MLP - x_continuous_transformed Shape: {x_continuous_transformed.shape}\")  # 확인: (1024, total_continuous_feature_dim * embedding_dim)\n",
    "\n",
    "        # Concatenate embeddings and continuous features\n",
    "        combined_features = torch.cat([embed_x, x_continuous_transformed], dim=1)  # (batch_size, mlp_input_dim) = (1024, (4+68)*64=4608)\n",
    "        # print(f\"MLP - Combined Features Shape: {combined_features.shape}\")  # 확인: (1024, mlp_input_dim)\n",
    "        \n",
    "        # MLP forward pass\n",
    "        mlp_y = self.mlp_layers(combined_features)  # (batch_size, 1)\n",
    "        # print(f\"MLP - MLP Output Shape: {mlp_y.shape}\")  # 확인: (1024, 1)\n",
    "        return mlp_y\n",
    "\n",
    "    def forward(self, x_categorical, x_continuous):\n",
    "        # x_categorical: (batch_size, num_categorical_features)\n",
    "        # x_continuous: (batch_size, total_continuous_feature_dim)\n",
    "\n",
    "        # FM component\n",
    "        fm_y = self.fm(x_categorical, x_continuous)  # (batch_size, 1)\n",
    "        \n",
    "        # MLP component\n",
    "        mlp_y = self.mlp(x_categorical, x_continuous)  # (batch_size, 1)\n",
    "        \n",
    "        # Combine FM and MLP components\n",
    "        y = fm_y + mlp_y\n",
    "        \n",
    "        return y.squeeze(1)  # (batch_size,) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Device 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Dims: [31360, 6807]\n",
      "num_categorical_features: 2\n",
      "total_continuous_feature_dim: 19\n",
      "embedding_dim: 32\n",
      "Calculated MLP Input Dimension: 672\n"
     ]
    }
   ],
   "source": [
    "# 각 범주형 변수의 고유값 개수\n",
    "user_dim = all_data['user_encoded'].nunique()\n",
    "item_dim = all_data['item_encoded'].nunique()\n",
    "\n",
    "\n",
    "# 범주형 변수의 고유값 개수를 리스트로 전달\n",
    "input_dims = [user_dim, item_dim] \n",
    "\n",
    "# 임베딩 차원 설정\n",
    "embedding_dim = 32\n",
    "\n",
    "# MLP 레이어 차원 설정\n",
    "mlp_dims = [64, 32, 16]\n",
    "\n",
    "# 드롭아웃 비율 설정\n",
    "drop_rate = 0.1\n",
    "\n",
    "# DeepFM 모델 초기화\n",
    "model = DeepFM(input_dims=input_dims, \n",
    "               embedding_dim=embedding_dim, mlp_dims=mlp_dims, drop_rate=drop_rate).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairwiseRecommendationDataset(Dataset):\n",
    "    def __init__(self, user_col, item_col, user_item_dict, all_items, item_probs, user_item_embeddings, num_negatives=1):\n",
    "        self.user_col = user_col.cpu()\n",
    "        self.item_col = item_col.cpu()\n",
    "        self.user_item_dict = user_item_dict\n",
    "        self.all_items = np.array(all_items)\n",
    "        self.item_probs = item_probs\n",
    "        self.num_negatives = num_negatives\n",
    "        self.user_item_embeddings = user_item_embeddings  # 사용자-아이템 임베딩\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user_col)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        user = self.user_col[idx]\n",
    "        pos_item = self.item_col[idx]\n",
    "\n",
    "        # Negative 샘플링: 사용자-아이템 임베딩 유사도 기반\n",
    "        neg_items = self.sample_similarity_negatives(user)\n",
    "\n",
    "        return user, pos_item, torch.tensor(neg_items, dtype=torch.long)\n",
    "\n",
    "    def sample_similarity_negatives(self, user):\n",
    "        user_id = user.item()\n",
    "        seen_items = self.user_item_dict[user_id]\n",
    "\n",
    "        # 유저 임베딩\n",
    "        user_embedding = self.user_item_embeddings[user_id]\n",
    "        # 모든 아이템 임베딩과의 유사도 계산 (Cosine Similarity)\n",
    "        item_embeddings = self.user_item_embeddings[len(self.user_item_dict):]\n",
    "        similarities = np.dot(item_embeddings, user_embedding) / (\n",
    "            np.linalg.norm(item_embeddings, axis=1) * np.linalg.norm(user_embedding)\n",
    "        )\n",
    "\n",
    "        # 유사도가 낮은 아이템 중 Negative 샘플 선택\n",
    "        neg_items = []\n",
    "        while len(neg_items) < self.num_negatives:\n",
    "            neg_item = np.random.choice(self.all_items, p=self.item_probs)\n",
    "            if neg_item not in seen_items:\n",
    "                neg_items.append(neg_item)\n",
    "        return neg_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LambdaRankLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LambdaRankLoss, self).__init__()\n",
    "\n",
    "    def forward(self, pos_preds, neg_preds):\n",
    "        \"\"\"\n",
    "        pos_preds: Positive 샘플의 예측값 (batch_size,)\n",
    "        neg_preds: Negative 샘플의 예측값 (batch_size, num_negatives)\n",
    "        \"\"\"\n",
    "        # Difference between positive and negative predictions\n",
    "        diff = pos_preds.unsqueeze(1) - neg_preds  # (batch_size, num_negatives)\n",
    "        # LambdaRank Loss 계산\n",
    "        loss = -torch.log(torch.sigmoid(diff) + 1e-8).sum(dim=1).mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_695831/2962419290.py:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1695392020201/work/torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  genre_col = torch.tensor(all_data['genre_embedding'].tolist(), dtype=torch.float32).to(device)\n"
     ]
    }
   ],
   "source": [
    "# 유저별 시청 아이템 딕셔너리 생성\n",
    "user_item_dict = all_data.groupby('user_encoded')['item_encoded'].apply(set).to_dict()\n",
    "\n",
    "# Categorical Features (long 타입)\n",
    "user_col = torch.tensor(all_data['user_encoded'].values, dtype=torch.long).to(device)\n",
    "item_col = torch.tensor(all_data['item_encoded'].values, dtype=torch.long).to(device)\n",
    "\n",
    "# Continuous Features (float 타입)\n",
    "genre_col = torch.tensor(all_data['genre_embedding'].tolist(), dtype=torch.float32).to(device)\n",
    "\n",
    "# 'year'를 numpy 배열로 미리 준비\n",
    "all_years = all_data['year'].values\n",
    "\n",
    "# DataLoader 생성\n",
    "dataset = PairwiseRecommendationDataset(\n",
    "    user_col=user_col,\n",
    "    item_col=item_col,\n",
    "    user_item_dict=user_item_dict,\n",
    "    all_items=all_items,\n",
    "    item_probs=item_probs,\n",
    "    user_item_embeddings=user_item_embeddings,\n",
    "    num_negatives=10  # Negative 샘플 수\n",
    ")\n",
    "train_loader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pairwise(model, train_loader, optimizer, epochs=10):\n",
    "    model.train()\n",
    "    criterion = LambdaRankLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for user, pos_item, neg_items in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            user = user.to(device, dtype=torch.long)\n",
    "            pos_item = pos_item.to(device, dtype=torch.long)\n",
    "            neg_items = neg_items.to(device, dtype=torch.long)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Positive 샘플\n",
    "            pos_genre = genre_col[pos_item]\n",
    "            pos_year = torch.tensor(all_years[pos_item.cpu().numpy()], dtype=torch.float32, device=device).unsqueeze(1)\n",
    "            pos_continuous = torch.cat([pos_genre, pos_year], dim=1)\n",
    "            x_categorical_pos = torch.stack([user, pos_item], dim=1)\n",
    "            pos_preds = model(x_categorical_pos, pos_continuous)\n",
    "\n",
    "            # Negative 샘플\n",
    "            neg_items_flat = neg_items.view(-1)\n",
    "            user_neg = user.unsqueeze(1).expand(-1, neg_items.shape[1]).reshape(-1)\n",
    "            neg_genre = genre_col[neg_items_flat]\n",
    "            neg_year = torch.tensor(all_years[neg_items_flat.cpu().numpy()], dtype=torch.float32, device=device).unsqueeze(1)\n",
    "            neg_continuous = torch.cat([neg_genre, neg_year], dim=1)\n",
    "            x_categorical_neg = torch.stack([user_neg, neg_items_flat], dim=1)\n",
    "            neg_preds = model(x_categorical_neg, neg_continuous).view(neg_items.shape[0], neg_items.shape[1])\n",
    "\n",
    "            # LambdaRank Loss 계산\n",
    "            loss = criterion(pos_preds, neg_preds)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('deepfm_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   5%|▌         | 4316/80539 [07:22<2:10:15,  9.75it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 모델 학습\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtrain_pairwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m, in \u001b[0;36mtrain_pairwise\u001b[0;34m(model, train_loader, optimizer, epochs)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      7\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m user, pos_item, neg_items \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      9\u001b[0m         user \u001b[38;5;241m=\u001b[39m user\u001b[38;5;241m.\u001b[39mto(device, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m     10\u001b[0m         pos_item \u001b[38;5;241m=\u001b[39m pos_item\u001b[38;5;241m.\u001b[39mto(device, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[11], line 18\u001b[0m, in \u001b[0;36mPairwiseRecommendationDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     15\u001b[0m pos_item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_col[idx]\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Negative 샘플링: 인기도 기반\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m neg_items \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_popularity_negatives\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m user, pos_item, torch\u001b[38;5;241m.\u001b[39mtensor(neg_items, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n",
      "Cell \u001b[0;32mIn[11], line 29\u001b[0m, in \u001b[0;36mPairwiseRecommendationDataset.sample_popularity_negatives\u001b[0;34m(self, user)\u001b[0m\n\u001b[1;32m     26\u001b[0m neg_items \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(neg_items) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_negatives:\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# 아이템 인기도에 따라 아이템을 샘플링\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     neg_item \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem_probs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m neg_item \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m seen_items:\n\u001b[1;32m     31\u001b[0m         neg_items\u001b[38;5;241m.\u001b[39mappend(neg_item)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 옵티마이저 설정\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "# 모델 학습\n",
    "train_pairwise(model, train_loader, optimizer, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_top_k(model, user_item_dict, all_items, k=10):\n",
    "    \"\"\"\n",
    "    모델을 사용하여 모든 유저에 대해 상위 K개의 영화를 추천합니다.\n",
    "    \n",
    "    Args:\n",
    "    - model: 훈련된 DeepFM 모델.\n",
    "    - user_item_dict: 유저별 시청한 영화 딕셔너리 {user_id: set(movies_seen)}.\n",
    "    - all_items: 전체 아이템 리스트.\n",
    "    - k: 추천할 영화 개수.\n",
    "    \n",
    "    Returns:\n",
    "    - recommendations: 추천 결과 리스트 [{\"user\": user_id, \"item\": movie_id}, ...]\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    recommendations = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for user_id in user_item_dict.keys():\n",
    "            # 유저가 본 적 없는 영화\n",
    "            unseen_items = list(set(all_items) - user_item_dict[user_id])\n",
    "            \n",
    "            if len(unseen_items) == 0:\n",
    "                continue  # 모든 영화를 이미 본 경우\n",
    "            \n",
    "            # 유저 ID와 미시청 영화 ID 텐서 생성\n",
    "            user_tensor = torch.tensor([user_id] * len(unseen_items), dtype=torch.long, device=device)\n",
    "            item_tensor = torch.tensor(unseen_items, dtype=torch.long, device=device)\n",
    "            \n",
    "            # Title과 Genre 임베딩\n",
    "            genre_tensor = genre_col[item_tensor].to(device)\n",
    "            \n",
    "            # Year과 Watch Year\n",
    "            year_tensor = torch.tensor(\n",
    "                all_data['year'].values[item_tensor.cpu().numpy()],\n",
    "                dtype=torch.float32,\n",
    "                device=device\n",
    "            ).unsqueeze(1)\n",
    "            \n",
    "            watch_year_tensor = torch.tensor(\n",
    "                all_data['watch_year'].values[item_tensor.cpu().numpy()],\n",
    "                dtype=torch.float32,\n",
    "                device=device\n",
    "            ).unsqueeze(1)\n",
    "            \n",
    "            # Continuous Features 결합\n",
    "            continuous_features = torch.cat([genre_tensor, year_tensor, watch_year_tensor], dim=1)\n",
    "            \n",
    "            # Categorical Features 결합\n",
    "            categorical_features = torch.stack([user_tensor, item_tensor], dim=1)\n",
    "            \n",
    "            # 모델로 점수 예측\n",
    "            scores = model(categorical_features, continuous_features)\n",
    "            \n",
    "            # 상위 K개 아이템 선택\n",
    "            top_k_indices = torch.topk(scores, k=k).indices.cpu().numpy()\n",
    "            top_k_items = item_tensor[top_k_indices].cpu().numpy()\n",
    "            \n",
    "            # 추천 결과 저장\n",
    "            for item_id in top_k_items:\n",
    "                recommendations.append({\"user\": user_id, \"item\": item_id})\n",
    "    \n",
    "    return recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'recommend_top_k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 2. 추천 결과를 원래의 ID로 복원하여 데이터프레임 생성\u001b[39;00m\n\u001b[1;32m      6\u001b[0m recommendation_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 8\u001b[0m recommendations \u001b[38;5;241m=\u001b[39m \u001b[43mrecommend_top_k\u001b[49m(model, user_item_dict, all_items, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m user_encoded, item_encoded_list \u001b[38;5;129;01min\u001b[39;00m recommendations\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# 원래의 유저 ID로 변환\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     user \u001b[38;5;241m=\u001b[39m user_id[user_encoded]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'recommend_top_k' is not defined"
     ]
    }
   ],
   "source": [
    "# 1. 인코딩된 ID를 원래의 ID로 매핑하기 위한 딕셔너리 생성\n",
    "user_id = dict(zip(all_data['user_encoded'], all_data['user']))\n",
    "item_id = dict(zip(all_data['item_encoded'], all_data['item']))\n",
    "\n",
    "# 2. 추천 결과를 원래의 ID로 복원하여 데이터프레임 생성\n",
    "recommendation_list = []\n",
    "\n",
    "recommendations = recommend_top_k(model, user_item_dict, all_items, k=10)\n",
    "\n",
    "for user_encoded, item_encoded_list in recommendations.items():\n",
    "    # 원래의 유저 ID로 변환\n",
    "    user = user_id[user_encoded]\n",
    "    \n",
    "    for item_encoded in item_encoded_list:\n",
    "        # 원래의 아이템 ID로 변환\n",
    "        item = item_id[item_encoded]\n",
    "        \n",
    "        # 추천 결과 추가\n",
    "        recommendation_list.append({\n",
    "            'user': user,\n",
    "            'item': item\n",
    "        })\n",
    "\n",
    "# 추천 결과를 데이터프레임으로 변환\n",
    "recommendations_df = pd.DataFrame(recommendation_list)\n",
    "\n",
    "# 3. CSV 파일로 저장\n",
    "recommendations_df.to_csv('recommendations.csv', index=False)\n",
    "print(\"추천 결과가 'recommendations.csv' 파일로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
