{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/train'\n",
    "train_df = pd.read_csv(os.path.join(data_path, 'train_ratings.csv'))\n",
    "train_df['watched'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_encoder = LabelEncoder()\n",
    "item_encoder = LabelEncoder()\n",
    "\n",
    "train_df['user_id'] = user_encoder.fit_transform(train_df['user'])\n",
    "train_df['item_id'] = item_encoder.fit_transform(train_df['item'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_negative_samples(train_df, num_items, max_negative_per_user=10, negative_ratio=0.5, random_seed=42):\n",
    "    \"\"\"\n",
    "    네거티브 샘플 반환\n",
    "    \"\"\"\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    users = train_df['user_id'].unique()\n",
    "    positive_interactions = set(zip(train_df['user_id'], train_df['item_id']))\n",
    "    all_items = set(range(num_items))  # Assuming item IDs are from 0 to num_items - 1\n",
    "    \n",
    "    negative_samples = []\n",
    "    \n",
    "    # 유저별로 진행\n",
    "    for user in tqdm(users, desc=\"Generating negative samples\", unit=\"user\"):\n",
    "        user_items = train_df[train_df['user_id'] == user]['item_id'].tolist()\n",
    "        num_user_items = len(user_items)\n",
    "        non_interacted_items = list(all_items - set(user_items))\n",
    "\n",
    "        # 샘플링 조건\n",
    "        if num_user_items <= 500:\n",
    "            num_negative = int(num_user_items * negative_ratio)\n",
    "        else:\n",
    "            num_negative = max_negative_per_user\n",
    "\n",
    "        # 네거티브 샘플링\n",
    "        sampled_items = np.random.choice(non_interacted_items, size=num_negative, replace=False)\n",
    "        for item in sampled_items:\n",
    "            if (user, item) not in positive_interactions:\n",
    "                negative_samples.append([user, item, 0])  # watched=0\n",
    "\n",
    "    # 결과 데이터프레임 생성\n",
    "    negative_df = pd.DataFrame(negative_samples, columns=['user_id', 'item_id', 'watched'])\n",
    "\n",
    "    return negative_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating negative samples: 100%|██████████| 31360/31360 [04:50<00:00, 108.07user/s]\n"
     ]
    }
   ],
   "source": [
    "num_items = train_df['item_id'].nunique()\n",
    "negative_df = generate_negative_samples(train_df, num_items, random_seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_df['user'] = user_encoder.inverse_transform(negative_df['user_id'])\n",
    "negative_df['item'] = item_encoder.inverse_transform(negative_df['item_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>time</th>\n",
       "      <th>watched</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>4643</td>\n",
       "      <td>1.230783e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>170</td>\n",
       "      <td>1.230783e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>531</td>\n",
       "      <td>1.230783e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>616</td>\n",
       "      <td>1.230783e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>2140</td>\n",
       "      <td>1.230783e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7318594</th>\n",
       "      <td>138493</td>\n",
       "      <td>177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>31359</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7318595</th>\n",
       "      <td>138493</td>\n",
       "      <td>43832</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>31359</td>\n",
       "      <td>4863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7318596</th>\n",
       "      <td>138493</td>\n",
       "      <td>2791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>31359</td>\n",
       "      <td>1547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7318597</th>\n",
       "      <td>138493</td>\n",
       "      <td>55267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>31359</td>\n",
       "      <td>5328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7318598</th>\n",
       "      <td>138493</td>\n",
       "      <td>8861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>31359</td>\n",
       "      <td>4057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7318599 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           user   item          time  watched  user_id  item_id\n",
       "0            11   4643  1.230783e+09        1        0     2505\n",
       "1            11    170  1.230783e+09        1        0      109\n",
       "2            11    531  1.230783e+09        1        0      319\n",
       "3            11    616  1.230783e+09        1        0      368\n",
       "4            11   2140  1.230783e+09        1        0     1183\n",
       "...         ...    ...           ...      ...      ...      ...\n",
       "7318594  138493    177           NaN        0    31359      115\n",
       "7318595  138493  43832           NaN        0    31359     4863\n",
       "7318596  138493   2791           NaN        0    31359     1547\n",
       "7318597  138493  55267           NaN        0    31359     5328\n",
       "7318598  138493   8861           NaN        0    31359     4057\n",
       "\n",
       "[7318599 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 기존 데이터와 병합\n",
    "final_data = pd.concat([train_df, negative_df])\n",
    "final_data.reset_index(drop=True, inplace=True)\n",
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDAEModel(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=128, dropout_rate=0.1):\n",
    "        super(CDAEModel, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "        self.hidden_layer1 = nn.Linear(embedding_dim, 1024)\n",
    "        self.hidden_layer2 = nn.Linear(1024, embedding_dim)\n",
    "        self.output_layer = nn.Linear(embedding_dim, num_items)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.leaky_relu = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, user_input, item_input):\n",
    "        user_embedded = self.user_embedding(user_input).squeeze(1)  # (batch_size, embedding_dim)\n",
    "        item_embedded = self.item_embedding(item_input).squeeze(1)\n",
    "        \n",
    "        hidden = self.leaky_relu(self.hidden_layer1(item_embedded))\n",
    "        hidden = self.leaky_relu(self.hidden_layer2(hidden))\n",
    "        \n",
    "        combined = user_embedded + hidden\n",
    "        # combined = torch.cat([user_embedded, hidden], dim=1)\n",
    "        # combined = self.leaky_relu(self.fc_combined(combined))  # Optional FC layer\n",
    "\n",
    "        output = torch.sigmoid(self.output_layer(combined))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CDAE 모델 인스턴스 생성\n",
    "num_users = train_df['user_id'].nunique()\n",
    "num_items = train_df['item_id'].nunique()\n",
    "model = CDAEModel(num_users, num_items, embedding_dim=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractionDataset(Dataset):\n",
    "    def __init__(self, data, num_items):\n",
    "        \"\"\"\n",
    "        data: DataFrame with columns ['user_id', 'item_id', 'watched']\n",
    "        num_items: Total number of unique items\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.num_items = num_items\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        user_id = row['user_id']\n",
    "        item_id = int(row['item_id'])\n",
    "        \n",
    "        label = torch.zeros(self.num_items)\n",
    "        label[item_id] = row['watched']  # 1 for positive, 0 for negative\n",
    "        \n",
    "        return user_id, item_id, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, epoch, filepath=\"model_checkpoint.pth\"):\n",
    "    \"\"\"\n",
    "    Save the model's state and optimizer state for resuming training.\n",
    "    \"\"\"\n",
    "    checkpoint = {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'epoch': epoch,\n",
    "    }\n",
    "    torch.save(checkpoint, filepath)\n",
    "    print(f\"Checkpoint saved to {filepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data, num_items, num_epochs=10, batch_size=128, learning_rate=0.001, device='cuda'):\n",
    "    \"\"\"\n",
    "    Train the CDAE model.\n",
    "    Args:\n",
    "        model: CDAE model instance\n",
    "        train_data: DataFrame with columns ['user_id', 'item_id', 'watched']\n",
    "        num_items: Total number of unique items\n",
    "        num_epochs: Number of training epochs\n",
    "        batch_size: Batch size for DataLoader\n",
    "        learning_rate: Learning rate for optimizer\n",
    "        device: Device to train on ('cuda' or 'cpu')\n",
    "    \"\"\"\n",
    "    # Prepare dataset and dataloader\n",
    "    dataset = InteractionDataset(train_data, num_items)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Loss function and optimizer\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Move model to device\n",
    "    model.to(device)\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    try:\n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_loss = 0.0\n",
    "            with tqdm(dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs}\", unit=\"batch\") as t:\n",
    "                for user_input, item_input, labels in t:\n",
    "                    user_input = user_input.to(device).long()\n",
    "                    item_input = item_input.to(device).long()\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # Forward pass\n",
    "                    outputs = model(user_input, item_input)\n",
    "\n",
    "                    # Compute loss\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    epoch_loss += loss.item()\n",
    "\n",
    "                    # Backward pass and optimization\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    t.set_postfix(loss=loss.item())\n",
    "\n",
    "            print(f\"Epoch {epoch + 1} Loss: {epoch_loss / len(dataloader):.5f}\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Training interrupted.\")\n",
    "        save_checkpoint(model, optimizer, epoch + 1, \"model_checkpoint.pth\")\n",
    "        return model, optimizer, epoch\n",
    "    \n",
    "    print(\"Training complete!\")\n",
    "    save_checkpoint(model, optimizer, epoch + 1, \"model_checkpoint.pth\")\n",
    "    return model, optimizer, epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 57177/57177 [15:19<00:00, 62.20batch/s, loss=7.57e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.00026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 57177/57177 [15:35<00:00, 61.15batch/s, loss=6.48e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 0.00008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 57177/57177 [15:30<00:00, 61.42batch/s, loss=5.08e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 0.00007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 57177/57177 [15:21<00:00, 62.03batch/s, loss=8.91e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 0.00006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:   4%|▍         | 2174/57177 [00:36<15:13, 60.24batch/s, loss=7.73e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training interrupted.\n",
      "Checkpoint saved to model_checkpoint.pth\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "trained_model, optimizer, last_epoch = train_model(model, final_data, num_items, num_epochs=10, batch_size=128, learning_rate=0.001, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath, model, optimizer=None, device='cuda'):\n",
    "    \"\"\"\n",
    "    Load the model and optimizer state from a checkpoint for resuming training.\n",
    "    \"\"\"\n",
    "    checkpoint = torch.load(filepath, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(\"Model state loaded.\")\n",
    "    \n",
    "    if optimizer:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        print(\"Optimizer state loaded.\")\n",
    "    \n",
    "    epoch = checkpoint['epoch']\n",
    "    print(f\"Resuming from epoch {epoch}\")\n",
    "    return epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def continue_training(model, train_data, num_items, checkpoint_path, num_epochs=10, batch_size=128, learning_rate=0.001, device='cuda'):\n",
    "    \"\"\"\n",
    "    Continue training from a saved checkpoint.\n",
    "    Args:\n",
    "        model: CDAE model instance.\n",
    "        train_data: DataFrame with training data.\n",
    "        num_items: Total number of unique items.\n",
    "        checkpoint_path: Path to the saved checkpoint.\n",
    "        num_epochs: Total number of epochs to train.\n",
    "        batch_size: Batch size for DataLoader.\n",
    "        learning_rate: Learning rate for optimizer.\n",
    "        device: Device to train on ('cuda' or 'cpu').\n",
    "    \"\"\"\n",
    "    # Prepare dataset and dataloader\n",
    "    dataset = InteractionDataset(train_data, num_items)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Loss function and optimizer\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Load checkpoint\n",
    "    start_epoch = 0\n",
    "    if checkpoint_path:\n",
    "        start_epoch = load_checkpoint(checkpoint_path, model, optimizer, device)\n",
    "\n",
    "    # Move model to device\n",
    "    model.to(device)\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    try:\n",
    "        for epoch in range(start_epoch, num_epochs):\n",
    "            epoch_loss = 0.0\n",
    "            with tqdm(dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs}\", unit=\"batch\") as t:\n",
    "                for user_input, item_input, labels in t:\n",
    "                    user_input = user_input.to(device).long()\n",
    "                    item_input = item_input.to(device).float()\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # Forward pass\n",
    "                    outputs = model(user_input, item_input)\n",
    "\n",
    "                    # Compute loss\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    epoch_loss += loss.item()\n",
    "\n",
    "                    # Backward pass and optimization\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    t.set_postfix(loss=loss.item())\n",
    "\n",
    "            print(f\"Epoch {epoch + 1} Loss: {epoch_loss / len(dataloader):.4f}\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Training interrupted.\")\n",
    "        save_checkpoint(model, optimizer, epoch + 1, f\"model_checkpoint{epoch + 1}.pth\")\n",
    "        return model, optimizer, epoch\n",
    "    \n",
    "    print(\"Training complete!\")\n",
    "    save_checkpoint(model, optimizer, epoch + 1, f\"model_checkpoint{epoch + 1}.pth\")\n",
    "    return model, optimizer, epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 재학습용\n",
    "new_model = CDAEModel(num_users, num_items, embedding_dim=128)\n",
    "\n",
    "model = continue_training(new_model, final_data, num_items, checkpoint_path=\"model_checkpoint3.pth\", num_epochs=20, batch_size=128, learning_rate=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state loaded.\n",
      "Resuming from epoch 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CDAEModel(num_users, num_items, embedding_dim=128)\n",
    "\n",
    "# 저장된 체크포인트에서 모델 불러오기 (체크포인트 이름 확인!)\n",
    "load_checkpoint(\"model_checkpoint.pth\", model, device='cuda')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추천"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_top_k(model, final_data, num_users, k=10, device='cuda'):\n",
    "    \"\"\"\n",
    "    Recommend top K items for each user based on the trained model.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    all_recommendations = {}\n",
    "    all_items = set(final_data['item_id'].unique())  # 전체 아이템 집합\n",
    "\n",
    "    with tqdm(total=num_users, desc=\"Recommending\", unit=\"user\") as pbar:\n",
    "        for user_id in range(num_users):\n",
    "            # 유저가 상호작용한 아이템\n",
    "            interacted_items = final_data[(final_data['user_id'] == user_id) & (final_data['watched'] == 1)]['item_id'].tolist()\n",
    "            \n",
    "            # 추천 후보 아이템: 상호작용하지 않은 전체 아이템\n",
    "            candidates = list(all_items - set(interacted_items))\n",
    "\n",
    "            # 유저 ID와 후보 아이템 ID를 텐서로 변환\n",
    "            user_input = torch.tensor([user_id], dtype=torch.long, device=device)\n",
    "            user_embedded = model.user_embedding(user_input).squeeze(0)  # (embedding_dim,)\n",
    "\n",
    "            # 후보 아이템 임베딩 계산\n",
    "            candidate_input = torch.tensor(candidates, dtype=torch.long, device=device)\n",
    "            candidate_embedded = model.item_embedding(candidate_input)  # (num_candidates, embedding_dim)\n",
    "            \n",
    "            # 점수 계산 (유저-아이템 내적)\n",
    "            with torch.no_grad():\n",
    "                scores = torch.matmul(candidate_embedded, user_embedded)  # (len(candidates),)\n",
    "\n",
    "             # Top K 추천\n",
    "            top_k_indices = torch.topk(scores, k=min(k, len(candidates))).indices.cpu().numpy()\n",
    "            top_k_items = [candidates[idx] for idx in top_k_indices]\n",
    "\n",
    "            # 결과 저장\n",
    "            all_recommendations[user_id] = top_k_items[:k]\n",
    "            pbar.update(1)\n",
    "\n",
    "    return all_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recommending: 100%|██████████| 31360/31360 [16:01<00:00, 32.63user/s]\n"
     ]
    }
   ],
   "source": [
    "recommendations = recommend_top_k(model, final_data, num_users, num_items, k=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user_id, item_ids in recommendations.items():\n",
    "    if len(item_ids) != 10:\n",
    "        print(f\"User {user_id} has {len(item_ids)} recommendations instead of 10.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "추천 결과가 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# CSV 파일에 저장할 때, 처음에는 헤더를 포함하고, 이후에는 추가로 저장\n",
    "header = True\n",
    "chunk_size = 1000  # 한 번에 처리할 사용자 수\n",
    "\n",
    "rows = []\n",
    "for i, (user_id, item_ids) in enumerate(recommendations.items()):\n",
    "    original_user_id = user_encoder.inverse_transform([user_id])[0]\n",
    "    original_item_ids = item_encoder.inverse_transform(item_ids)\n",
    "    for item_id in original_item_ids:\n",
    "        rows.append([original_user_id, item_id])\n",
    "    \n",
    "    # 청크 크기만큼 처리한 후 저장\n",
    "    if (i + 1) % chunk_size == 0 or i == len(recommendations) - 1:\n",
    "        df = pd.DataFrame(rows, columns=[\"user\", \"item\"])\n",
    "        df.to_csv('cdae_rec3.csv', mode='w', header=header, index=False)\n",
    "        header = False  # 이후에는 헤더를 포함하지 않음\n",
    "        rows = []  # 저장 후 리스트 초기화\n",
    "\n",
    "print(\"추천 결과가 저장되었습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
